[["data.html", "Chapter 3 Data 3.1 Sources 3.2 Cleaning / transformation 3.3 Missing value analysis", " Chapter 3 Data 3.1 Sources As described in the proposal, we look at three types of data over time: 3.1.1 Crime Crime data is sourced using the Uniform Crime Reporting (UCR) program. More than 18,000 law enforcement agencies at different administrative levels (from federal to city) voluntarily submit data to the state UCR or directly to FBI’s UCR. The UCR program is used by criminal justice researchers and students. Yearwise UCR data is visited using the index of UCR publications. In the proposal, we had planned to extract data of 1995 to 1998 as well, but these are in pdf format and was turning out to be rather difficult to extract. Besides, we can take data from 1999 as well to roughly compare the Bush administration vs the Obama administration in terms of crime. From 1999 to 2019, crime data is directly available in Table 5 (except for 2016, where the data is available in Table 3) in xls format categorized by state, nature of offense and kind of area. 3.1.2 Imprisonment Imprisonment data is sourced from the National Prisoner Statistics (NPS) program. The Bureau of Justice Statistics has compiled data from NPS as quick tables. We use total number of prison admissions from 1978 to 2019, and total number of prison releases from 1978 to 2019. In the proposal we only decided upon the previously mentioned dataset, however we are also exploring imprisonment rate of sentenced prisoners from 1978 to 2019. This will allow us to see the rate which is the number of prisoners under state or federal jurisdiction with a sentence of more than 1 year per 100,000 U.S. residents. 3.2 Cleaning / transformation 3.2.1 Crime Raw crime data across all years is made in Excel and doesn’t have a clear table structure. For example, Snapshot of data Data from 1999-2002 have a similar format so they are extracted using data_collection/1999-2002.R. Data from 2003 and 2004 are peculiar so they ar extracted using data_collection/2003.R and data_collection/2004.R. Data from 2013-2016 have a similar format so they are extracted using data_collection/2013-2016.R. The rest of the data is extracted using data_collection/2005-2012, 2017-2019.R. The xls links to these years is saved in metadata/crime_data_links.csv so that we don’t have to hardcode URLs. library(dplyr) library(readxl) crimes_links &lt;- read.csv(&#39;metadata/crime_data_links.csv&#39;) source(&quot;data_collection/1999-2002.R&quot;, local = knitr::knit_global()) source(&quot;data_collection/2003.R&quot;, local = knitr::knit_global()) source(&quot;data_collection/2004.R&quot;, local = knitr::knit_global()) source(&quot;data_collection/2005-2012, 2017-2019.R&quot;, local = knitr::knit_global()) source(&quot;data_collection/2013-2016.R&quot;, local = knitr::knit_global()) crime_all_data &lt;- NULL for(year in 1999:2002) { if(is.null(crime_all_data)) crime_all_data &lt;- getdata.1999(crimes_links, year) else crime_all_data = bind_rows(crime_all_data, getdata.1999(crimes_links, year)) } for(year in 2003:2003) crime_all_data = bind_rows(crime_all_data, getdata.2003(crimes_links, year)) for(year in 2004:2004) crime_all_data = bind_rows(crime_all_data, getdata.2004(crimes_links, year)) for(year in 2005:2012) crime_all_data = bind_rows(crime_all_data, getdata.2005(crimes_links, year)) for(year in 2013:2016) crime_all_data = bind_rows(crime_all_data, getdata.2013(crimes_links, year)) for(year in 2017:2019) crime_all_data = bind_rows(crime_all_data, getdata.2005(crimes_links, year)) Some of the states were read with a whitespace or a comma so we’ll clean that up. library(stringr) crime_all_data[&#39;State&#39;] &lt;- lapply(crime_all_data[&#39;State&#39;], function(x) str_trim(gsub(&#39;,&#39;, &#39;&#39;, x))) print(nrow(unique(crime_all_data[&#39;State&#39;]))) ## [1] 52 crime_all_data$State &lt;- as.factor(crime_all_data$State) As stated in the 2003 crime report summary, they started referring to rural counties as metropolitan counties, so we change the area name in the previous years for one-to-one correspondence. In the District of Columbia, the report saves the district-wide crime numbers as “Total” instead of “State Total” since DC is not technically a state. We change the label of that as well to “State Total” just for one-to-one correspondence. crime_all_data[crime_all_data[&#39;Area&#39;] == &#39;Rural&#39;, &#39;Area&#39;] &lt;- &#39;Nonmetropolitan counties&#39; crime_all_data[crime_all_data[&#39;Area&#39;] == &#39;Total&#39;, &#39;Area&#39;] &lt;- &#39;State Total&#39; unique(crime_all_data[&#39;Area&#39;]) ## Area ## 1 Metropolitan Statistical Area ## 2 Cities outside metropolitan areas ## 3 Nonmetropolitan counties ## 4 State Total crime_all_data$Area &lt;- as.factor(crime_all_data$Area) Finally, we also convert the year to a factor and the rest of the numbers to integer crime_all_data$Year &lt;- as.factor(crime_all_data$Year) crime_all_data$Population &lt;- as.numeric(crime_all_data$Population) crime_all_data$Violent &lt;- as.numeric(crime_all_data$Violent) crime_all_data$Property &lt;- as.numeric(crime_all_data$Property) crime_all_data$Murder &lt;- as.numeric(crime_all_data$Murder) crime_all_data$Rape &lt;- as.numeric(crime_all_data$Rape) crime_all_data$Robbery &lt;- as.numeric(crime_all_data$Robbery) crime_all_data$Assault &lt;- as.numeric(crime_all_data$Assault) crime_all_data$Burglary &lt;- as.numeric(crime_all_data$Burglary) crime_all_data$Theft &lt;- as.numeric(crime_all_data$Theft) crime_all_data$Motor &lt;- as.numeric(crime_all_data$Motor) crime_all_data$Arson &lt;- as.numeric(crime_all_data$Arson) 3.2.2 Imprisonment We initiate the exploration of imprisonment data by reading in the files using read_excel function. Then we proceed to eliminate extra columns such as “Jurisdiction” since it is not necessary to conduct our analysis. We also properly rename our desired columns into State, Year, and Number of Prisoners. # read in admissions excel file admissions_data &lt;- read_excel(&quot;data_collection/QT_total admissions_total.xlsx&quot;, na = c(&quot;/&quot;,&quot;--&quot;), skip = 10) # read in releases excel file releases_data &lt;- read_excel(&quot;data_collection/QT_total releases_total.xlsx&quot;, na = c(&quot;/&quot;,&quot;--&quot;), skip = 10) # read in imprisonment rate excel file rate_data &lt;- read_excel(&quot;data_collection/QT_imprisonment rate_total.xlsx&quot;, na = c(&quot;/&quot;,&quot;--&quot;), skip = 9) # remove the first column (get rid of jurisdiction) admissions_data &lt;- select(admissions_data, -c(1)) releases_data &lt;- select(releases_data, -c(1)) rate_data &lt;- select(rate_data, -c(1)) # rename column to State admissions_data &lt;- rename(admissions_data, State = &quot;...2&quot;) releases_data &lt;- rename(releases_data, State = &quot;...2&quot;) rate_data &lt;- rename(rate_data, State = &quot;...2&quot;) # filter out missing values admissions_data &lt;- filter(admissions_data, is.na(State) == FALSE) releases_data &lt;- filter(releases_data, is.na(State) == FALSE) rate_data &lt;- filter(rate_data, is.na(State) == FALSE) # get rid of side descriptions admissions_data &lt;- head(admissions_data, - 9) releases_data &lt;- head(releases_data, - 10) rate_data &lt;- head(rate_data, - 10) Next, we proceed to relabel the State and Year columns by removing extra characters that do not provide significance in our visualizations. # reformatting State columns bad &lt;- admissions_data[which(str_detect(admissions_data$State , &#39;[:punct:]&#39;)),]$State admissions_data[which(str_detect(admissions_data$State , &#39;[:punct:]&#39;)),]$State &lt;- str_sub(bad, end = -3) bad_1 &lt;- admissions_data[which(str_detect(releases_data$State , &#39;[:punct:]&#39;)),]$State releases_data[which(str_detect(releases_data$State , &#39;[:punct:]&#39;)),]$State &lt;- str_sub(bad_1, end = -2) bad_2 &lt;- admissions_data[which(str_detect(rate_data$State , &#39;[:punct:]&#39;)),]$State rate_data[which(str_detect(rate_data$State , &#39;[:punct:]&#39;)),]$State &lt;- str_sub(bad_2, end = -1) # rename certain year column admissions_data &lt;- rename(admissions_data, &#39;2013&#39; = &quot;2013/b&quot;) releases_data &lt;- rename(releases_data, &#39;2013&#39; = &quot;2013/b,c&quot;, &#39;2014&#39; = &#39;2014/c&#39;, &#39;2015&#39; = &#39;2015/c&#39;) All of the three tables are in xlsx format so we will use readxl package to import it into R. These tables have the total number of prison admissions, releases, and imprisonment rates by year and by state. The states are along a column and the years are along a row so we will pivot_longer() function so that the final table has state, year and number of prisoners admitted/released/rates as columns. library(&quot;tidyr&quot;) # admissions data to long format admissions_data_long &lt;- pivot_longer(admissions_data, cols = 2:ncol(admissions_data) , names_to = &quot;Year&quot;, values_to = &quot;Admissions&quot;) # releases data to long format releases_data_long &lt;- pivot_longer(releases_data, cols = 2:ncol(releases_data) , names_to = &quot;Year&quot;, values_to = &quot;Releases&quot;) # rate data to long format rate_data_long &lt;- pivot_longer(rate_data, cols = 2:ncol(rate_data) , names_to = &quot;Year&quot;, values_to = &quot;Rate&quot;) Now that we have converted all three data frames into the desired long format, we can proceed to apply an inner join on the admissions_data_long and releases_data_long by State and Year. Then we apply another inner join on the resulting data frame with the rate_data_long. Now we have one clean table that encapsulates five columns: State, Year, Admissions, Releases, and Rate and 1,512 rows of entries. # inner merge on admissions and releases data admissions_releases_data &lt;- merge(x=admissions_data_long, y=releases_data_long, by=c(&quot;State&quot;, &quot;Year&quot;)) # inner merge on admissions_releases_data and rate_data_long total_imprisonment_data &lt;- merge(x=admissions_releases_data, y=rate_data_long, by=c(&quot;State&quot;, &quot;Year&quot;)) # adding factor levels to State and Year total_imprisonment_data$State &lt;- as.factor(total_imprisonment_data$State) total_imprisonment_data$Year &lt;- as.numeric(total_imprisonment_data$Year) 3.3 Missing value analysis 3.3.1 Crime We visualize the missing data in the transformed crime data table library(naniar) vis_miss(crime_all_data) There are no missing values in Year, State, Area and Population. There are some missing values in crime categories other than arson, which we checked is actually blank in the raw data. For now, we will keep the missing values as they are and impute values based on the graphics we decide to plot. Arson has been blank or missing in all raw data across all years so we will drop that column. crime_all_data &lt;- crime_all_data[, -14] 3.3.2 Imprisonment There are missing values through Admissions, Releases, and Rate values across States. However, the numbers are quite insignificant in comparison to the available data that is present in the total_imprisonment_data data frame. library(&quot;ggplot2&quot;) # creating missing values list missing_values &lt;- total_imprisonment_data %&gt;% gather(key = &quot;key&quot;, value = &quot;val&quot;) %&gt;% mutate(isna = is.na(val)) %&gt;% group_by(key) %&gt;% mutate(total = n()) %&gt;% group_by(key, total, isna) %&gt;% summarise(num.isna = n()) %&gt;% mutate(pct = num.isna / total * 100) # leveling Missing v. Present levels &lt;- (missing_values %&gt;% filter(isna == T) %&gt;% arrange(desc(pct)))$key # bar chart of missing value percentages (total_imprisonment_data) missing_percentage_plot &lt;- missing_values %&gt;% ggplot() + geom_bar(aes(x = reorder(key, desc(pct)), y = pct, fill=isna), stat = &#39;identity&#39;, alpha=0.8) + geom_text(aes(x= reorder(key, desc(pct)), y = pct, label = round(pct, digits = 3))) + scale_x_discrete(limits = levels) + scale_fill_manual(name = &quot;&quot;, values = c(&#39;steelblue&#39;, &#39;tomato3&#39;), labels = c(&quot;Present&quot;, &quot;Missing&quot;)) + coord_flip() + labs(title = &quot;Percentage of missing values&quot;, x = &#39;Variable&#39;, y = &quot;% of missing values&quot;) # plotting each row in the dataset of missing values (total_imprisonment_data) missing_row_plot &lt;- total_imprisonment_data %&gt;% mutate(id = row_number()) %&gt;% gather(-id, key = &quot;key&quot;, value = &quot;val&quot;) %&gt;% mutate(isna = is.na(val)) %&gt;% ggplot(aes(key, id, fill = isna)) + geom_raster(alpha=0.8) + scale_fill_manual(name = &quot;&quot;, values = c(&#39;steelblue&#39;, &#39;tomato3&#39;), labels = c(&quot;Present&quot;, &quot;Missing&quot;)) + scale_x_discrete(limits = levels) + labs(x = &quot;Variable&quot;, y = &quot;Row Number&quot;, title = &quot;Missing values in rows&quot;) + coord_flip() According to the bar chart, Only 1.2% of Releases and Rate data are missing. Admissions takes the lead with 1.39% of missing values. We also plotted the missing values of rows in order to see if there is a pattern across different features. It seems that the missing values originate from a single row – indicating that they are related to a specific state. library(&quot;gridExtra&quot;) # for multiple plots grid.arrange(missing_percentage_plot, missing_row_plot, ncol = 2) Now we will highlight missing values of specific States. There some missing values for Alabama and New Hampshire for Admissions data. There are also missing values across all variables for District of Columbia from 2001-2019 since sentenced felons were the responsibility of the Federal Bureau of Prisons during these years. We will keep these entries since we are simply visualizing information provided from the National Prisoner Statistics (NPS) program. # getting missing values percentages missing_values_states &lt;- total_imprisonment_data %&gt;% group_by(State) %&gt;% summarise(Admissions = 100*length(grep(T, is.na(Admissions)))/ nrow(total_imprisonment_data), Releases = 100*length(grep(T, is.na(Releases)))/ nrow(total_imprisonment_data), Rate = 100*length(grep(T, is.na(Rate)))/ nrow(total_imprisonment_data)) %&gt;% pivot_longer(cols = c(-1)) %&gt;% rename(Missing = value, variable = name) %&gt;% mutate(Present = 100-Missing) %&gt;% pivot_longer(cols = c(-1:-2), names_to = &quot;NA_Status&quot;) %&gt;% filter(value &gt; 0 &amp; value &lt; 100) # highlighting missing states values missing_states_plot &lt;- missing_values_states %&gt;% ggplot() + facet_wrap(~ State) + geom_bar(aes(x = variable, y = value, fill=NA_Status), stat = &#39;identity&#39;, alpha=0.8) + geom_text(aes(x = variable, y = value, label = round(rev(value), digits = 3))) + #scale_x_discrete(limits = levels) + scale_fill_manual(name = &quot;&quot;, values = c(&#39;steelblue&#39;, &#39;tomato3&#39;), labels = c(&quot;Present&quot;, &quot;Missing&quot;)) + labs(title = &quot;Percentage of missing values&quot;, x = &#39;Variable&#39;, y = &quot;% of missing values&quot;, caption = &quot;Missing Values from District of Columbia and Alabama&quot;) missing_states_plot "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
